import os, json, httpx
from django.utils import timezone
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status, permissions, throttling
from pomi.apis.consultaSerializer import whatsAppIn
from pomi.apis.consultaServices import guardar_historico
import time
from dotenv import load_dotenv
import requests
from openai import OpenAI

# Cargar el el .env
load_dotenv()

RASA_URL = os.getenv("RASA_URL")

def call_openai_directly(query, context="", usuario_id="anonimo", model="ft:gpt-4o-mini-2024-07-18:personal:pomififvrs:BnAyJv1u"):
    """
    Funci√≥n auxiliar para llamar directamente a OpenAI sin pasar por la vista de Django
    """
    try:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("‚ùå No se encontr√≥ OPENAI_API_KEY en variables de entorno")
            return None
            
        messages = [
            {
                "role": "system",
                "content": (
                    "Responde como un asistente acad√©mico de la Universidad Peruana de Ciencias Aplicadas (UPC), "
                    "especializado exclusivamente en temas acad√©micos y administrativos de la UPC."
                )
            },
            {
                "role": "user",
                "content": f"{context}\n\n{query}" if context else query
            }
        ]
        
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.3
        )

        gpt_text = response.choices[0].message.content
        print(f"‚úÖ GPT gener√≥ respuesta para {usuario_id}")
        
        return {
            "status": "ok",
            "response": gpt_text
        }

    except Exception as e:
        import traceback
        print("‚ùå Error GPT:\n", traceback.format_exc())
        return {
            "error": str(e),
            "status": "error"
        }

class ChatWebhookView(APIView):
    permission_classes = [permissions.AllowAny]
    throttle_classes = [throttling.UserRateThrottle]
    
    def post(self, request):
        payload = whatsAppIn(data=request.data)
        payload.is_valid(raise_exception=True)
        data = payload.validated_data
        
        sender = data["sender"]
        user_text = data["text"]
        celular = data["from_number"]
        
        # Medir tiempo de inicio
        start_time = time.time()
        
        #1. Enviar a Rasa
        body = {"sender_id": sender, "message": user_text}
        print(f"üîÑ RASA_URL: {RASA_URL}")
        
        # Variable para controlar si usar OpenAI
        use_openai_fallback = False
        rasa_msg = []
        rasa_error_detail = ""
        
        try:
            print(f"üîÑ Enviando request a Rasa: {RASA_URL}")
            print(f"üì¶ Body enviado: {body}")
            
            r = requests.post(
                RASA_URL, 
                json=body, 
                timeout=5  # Timeout de 30 segundos
            )
            r.raise_for_status()
            
            # Validar que la respuesta no est√© vac√≠a
            if not r.content:
                print("‚ùå Respuesta vac√≠a de Rasa")
                use_openai_fallback = True
                rasa_error_detail = "Respuesta vac√≠a de Rasa"
            else:
                try:
                    rasa_msg = r.json()  # Rptas de Rasa
                    print(f"‚úÖ Status Code: {r.status_code}")
                    print(f"üì® Respuesta de Rasa: {rasa_msg}")
                except json.JSONDecodeError as json_error:
                    print(f"‚ùå Error al parsear JSON de Rasa: {json_error}")
                    print(f"üìÑ Contenido crudo: {r.text[:200]}...")
                    use_openai_fallback = True
                    rasa_error_detail = f"Error al parsear JSON: {json_error}"
                    
        except requests.Timeout:
            print("‚è∞ Timeout al conectar con Rasa - usando OpenAI como fallback")
            use_openai_fallback = True
            rasa_error_detail = "Timeout al conectar con Rasa"
            
        except requests.ConnectionError:
            print("üîå Error de conexi√≥n con Rasa - usando OpenAI como fallback")
            use_openai_fallback = True
            rasa_error_detail = "Error de conexi√≥n con Rasa"
            
        except requests.RequestException as e:
            print(f"‚ùå Error de request con Rasa: {str(e)} - usando OpenAI como fallback")
            use_openai_fallback = True
            rasa_error_detail = f"Error de request: {str(e)}"
        
        
        # Medir tiempo de fin de Rasa
        end_time = time.time()
        response_time = end_time - start_time
        
        # Procesar respuesta de Rasa solo si no hubo error de conexi√≥n
        whatsapp_msgs = []
        final_msg = ""
        
        if not use_openai_fallback:
            # Procesar respuesta de Rasa de forma m√°s robusta
            if not rasa_msg:
                print("‚ö†Ô∏è Respuesta de Rasa vac√≠a o None")
                use_openai_fallback = True
            elif isinstance(rasa_msg, dict):
                print("üìù Procesando respuesta como diccionario")
                if "response" in rasa_msg and rasa_msg["response"]:
                    whatsapp_msgs.append(str(rasa_msg["response"]))
                elif "text" in rasa_msg and rasa_msg["text"]:
                    whatsapp_msgs.append(str(rasa_msg["text"]))
                elif "custom" in rasa_msg and isinstance(rasa_msg["custom"], dict) and "gpt_response" in rasa_msg["custom"]:
                    whatsapp_msgs.append(str(rasa_msg["custom"]["gpt_response"]))
                else:
                    print(f"‚ö†Ô∏è Estructura de diccionario no reconocida: {rasa_msg}")
                    use_openai_fallback = True
            elif isinstance(rasa_msg, list):
                print(f"üìù Procesando respuesta como lista con {len(rasa_msg)} elementos")
                for i, msg in enumerate(rasa_msg):
                    print(f"  Elemento {i}: {type(msg)} - {msg}")
                    if isinstance(msg, dict):
                        if "text" in msg and msg["text"]:
                            whatsapp_msgs.append(str(msg["text"]))
                        elif "custom" in msg and isinstance(msg["custom"], dict) and "gpt_response" in msg["custom"]:
                            whatsapp_msgs.append(str(msg["custom"]["gpt_response"]))
                        elif "response" in msg and msg["response"]:
                            whatsapp_msgs.append(str(msg["response"]))
                    elif isinstance(msg, str) and msg.strip():
                        whatsapp_msgs.append(msg.strip())
            elif isinstance(rasa_msg, str):
                print("üìù Procesando respuesta como string")
                if rasa_msg.strip():
                    whatsapp_msgs.append(rasa_msg.strip())
                else:
                    use_openai_fallback = True
            else:
                print(f"‚ö†Ô∏è Tipo de respuesta no reconocido: {type(rasa_msg)}")
                use_openai_fallback = True

            # Limpiar mensajes vac√≠os y duplicados
            whatsapp_msgs = [msg.strip() for msg in whatsapp_msgs if msg and msg.strip()]
            whatsapp_msgs = list(dict.fromkeys(whatsapp_msgs))
            
            if whatsapp_msgs:
                final_msg = "\n".join(whatsapp_msgs)
                print(f"üîç Mensaje final de Rasa: '{final_msg}'")
                
                # Verificar patrones de error en la respuesta
                error_patterns = [
                    "‚ùå no puedo responder ahora", "no puedo responder ahora",
                    "no puedo responder", "lo siento, no pude procesar",
                    "no entiendo", "disculpa, no comprendo",
                    "no s√© c√≥mo ayudarte", "fallback", "default response", "acci√≥n default"
                ]
                
                final_msg_normalized = final_msg.lower().strip()
                
                if any(pattern in final_msg_normalized for pattern in error_patterns):
                    print(f"‚ö†Ô∏è Respuesta de Rasa contiene patr√≥n de error")
                    use_openai_fallback = True
                
                # Verificar si es muy gen√©rico o corto
                generic_responses = ["ok", "bien", "s√≠", "no", "gracias", "hola", "adi√≥s"]
                if len(final_msg_normalized) < 10 or final_msg_normalized in generic_responses:
                    print(f"‚ö†Ô∏è Mensaje demasiado gen√©rico o corto")
                    use_openai_fallback = True
            else:
                print("‚ö†Ô∏è No se pudieron extraer mensajes v√°lidos de Rasa")
                use_openai_fallback = True
        
        # Si hay que usar OpenAI como fallback
        if use_openai_fallback:
            print(f"ü§ñ Usando OpenAI como fallback. Raz√≥n: {rasa_error_detail or 'Respuesta inadecuada de Rasa'}")
            
            openai_context = f"El usuario pregunt√≥: '{user_text}'."
            if rasa_error_detail:
                openai_context += f" Rasa fall√≥: {rasa_error_detail}"
            
            try:
                openai_start_time = time.time()
                openai_response = call_openai_directly(
                    query=user_text,
                    context=openai_context,
                    usuario_id=sender
                )
                openai_response_time = time.time() - openai_start_time
                
                print(f"‚è±Ô∏è OpenAI respondi√≥ en {openai_response_time:.2f} segundos")
                print(f"üì® Respuesta de OpenAI: {openai_response}")
                
                if openai_response and openai_response.get("status") == "ok":
                    openai_text = openai_response.get("response", "").strip()
                    if openai_text and len(openai_text) > 5:
                        final_msg = openai_text
                        print(f"‚úÖ OpenAI respondi√≥ exitosamente")
                    else:
                        final_msg = "‚ùå Lo siento, no pude procesar tu consulta. Intenta reformular tu pregunta."
                else:
                    final_msg = "‚ùå Lo siento, no pude procesar tu consulta. Intenta m√°s tarde."
                    
            except Exception as e:
                print(f"‚ùå Excepci√≥n en OpenAI: {str(e)}")
                final_msg = "‚ùå Lo siento, no pude procesar tu consulta. Por favor, intenta nuevamente."
        
        # Validaciones finales
        if not final_msg or not final_msg.strip():
            final_msg = "‚ùå Lo siento, no pude procesar tu consulta en este momento."
        
        # Limpiar y formatear el mensaje correctamente
        final_msg = final_msg.strip()
        
        # Reemplazar m√∫ltiples saltos de l√≠nea por uno solo
        import re
        final_msg = re.sub(r'\n{3,}', '\n\n', final_msg)
        
        # Eliminar espacios al inicio y final de cada l√≠nea
        final_msg = '\n'.join(line.strip() for line in final_msg.split('\n'))
        
        if len(final_msg) > 2000:
            final_msg = final_msg[:1997] + "..."
        
        # Calcular tiempo total
        total_time = time.time() - start_time
        
        print(f"üíæ Mensaje final: '{final_msg[:100]}...'")
        print(f"‚è±Ô∏è Tiempo total: {round(total_time, 4)} segundos")
        
        # Guardar consulta y respuesta en el hist√≥rico
        try:
            datos_feedbackgpt = {
                "celular": celular,
                "sender_id": sender,
                "pregunta": user_text,
                "respuesta": final_msg,
                "tiempo": round(total_time, 4)
            }
            
            nuevo_registro = guardar_historico(datos_feedbackgpt)
            print(f"‚úÖ Registro guardado: ID {nuevo_registro.id if hasattr(nuevo_registro, 'id') else 'N/A'}")
            
        except Exception as e:
            print(f"‚ùå Error al guardar: {str(e)}")
        
        # Retornar la respuesta adaptada
        return Response(
            {
                "response": final_msg,
                "processing_time": round(total_time, 4),
                "timestamp": timezone.now().isoformat(),
                "fallback_used": use_openai_fallback
            },
            status=status.HTTP_200_OK
        )
        